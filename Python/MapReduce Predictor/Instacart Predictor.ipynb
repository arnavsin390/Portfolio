{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "# Useful function for printing rules out in readable format\n",
    "products = pd.read_csv(os.path.join('..', 'resource', 'asnlib', 'publicdata', 'products.csv.bz2'))\n",
    "product_table = dict(products[['product_id', 'product_name']].to_dict('tight')['data'])\n",
    "\n",
    "def print_rules(rules):\n",
    "    for LHS, RHS in rules:\n",
    "        if isinstance(LHS, int):\n",
    "            l_string = f'{LHS}'\n",
    "        else:\n",
    "            l_string = f'{\", \".join([product_table[p_id] for p_id in LHS])}'\n",
    "        if isinstance(RHS, int):\n",
    "            r_string = f'{RHS}'\n",
    "        else:\n",
    "            r_string = f'{\", \".join([product_table[p_id] for p_id in RHS])}'\n",
    "        print(f'{l_string} -> {r_string}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\"\"\"def map1(key, value, itemsets):\n",
    "    # Emit every product from every order\n",
    "    for product in value:\n",
    "        yield product, 1\n",
    "\n",
    "def reduce1(key, value):\n",
    "    # Emit every product that appears more than once\n",
    "    count = sum(value)\n",
    "    if count > 5:\n",
    "        yield (key,), count\n",
    "\n",
    "def map2(key, value, itemsets):\n",
    "    # Emit every pair of products in this order where both products are in the frequent itemsets\n",
    "    for pair in itertools.combinations([product for product in sorted(value) if (product,) in itemsets], 2):\n",
    "        yield pair, 1\n",
    "\n",
    "def reduce2(key, value):\n",
    "    # Emit every pair of products that appears more than once\n",
    "    count = sum(value)\n",
    "    if count > 5:\n",
    "        yield key, count\n",
    "\n",
    "# Define the sequence of functions to be run by the MapReduce \"platform\"\n",
    "stages = [map1, reduce1, map2, reduce2]\n",
    "\n",
    "# Transform frequent itemsets into association rules\n",
    "def itemsets2rules(itemsets):\n",
    "    rules = []\n",
    "    for itemset, value in itemsets.items():\n",
    "        if len(itemset) > 1:\n",
    "            # Puts last item on RHS, everything else on LHS\n",
    "            item_list = list(itemset)\n",
    "            rules.append((set(item_list[:-1]), set(item_list[-1:])))\n",
    "    return rules\n",
    "def precision_rules(itemsets):\n",
    "    return itemsets2rules(itemsets)\n",
    "def recall_rules(itemsets):\n",
    "    return itemsets2rules(itemsets)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "# Define mapper function 1\n",
    "def mapper1(order_id, products, frequent_itemsets):\n",
    "    output = {}\n",
    "    # Generate all possible pairs of products in the order\n",
    "    pairs = itertools.combinations(products, 2)\n",
    "    # Emit pairs that are not in the frequent itemsets dictionary with a count of 1\n",
    "    for pair in pairs:\n",
    "        if pair not in frequent_itemsets:\n",
    "            output[pair] = 1\n",
    "            # Add the new pair to the frequent itemsets dictionary\n",
    "            frequent_itemsets[pair] = 1\n",
    "        else:\n",
    "            frequent_itemsets[pair] += 1\n",
    "    return output.items()\n",
    "\n",
    "# Define mapper function 2\n",
    "def mapper2(order_id, products, frequent_itemsets):\n",
    "    output = {}\n",
    "    # Generate all possible pairs of products in the order\n",
    "    pairs = itertools.combinations(products, 2)\n",
    "    # Emit pairs that are in the frequent itemsets dictionary with a count of 1\n",
    "    for pair in pairs:\n",
    "        if pair in frequent_itemsets:\n",
    "            output[pair] = 1\n",
    "    return output.items()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define reducer function 1\n",
    "def reducer1(key, values):\n",
    "    # Count the occurrences of each product in the list of values\n",
    "    product_counts = collections.Counter(values)\n",
    "    # Yield key-value pair where the key is the itemset and the value is the total count\n",
    "    yield key, sum(product_counts.values())\n",
    "\n",
    "# Define reducer function 2\n",
    "def reducer2(key, values):\n",
    "    # Count the occurrences of each product in the list of values\n",
    "    product_counts = collections.Counter(values)\n",
    "    # Yield key-value pair where the key is the itemset and the value is the total count\n",
    "    yield key, sum(product_counts.values())\n",
    "\n",
    "# Define stages for MapReduce simulation\n",
    "stages = [\n",
    "    mapper1, reducer1,\n",
    "    mapper2, reducer2\n",
    "]\n",
    "\n",
    "# Define precision_rules function\n",
    "def precision_rules(frequent_itemsets):\n",
    "    rules = []\n",
    "    for itemset, count in frequent_itemsets.items():\n",
    "        if count > 100:  # Check if itemset occurs more than 10 times\n",
    "            for i in range(1, len(itemset)):\n",
    "                lhs = itemset[:i]\n",
    "                #print(\"lhs:\", lhs)\n",
    "                rhs = itemset[i:]\n",
    "                #print(\"rhs:\", rhs)\n",
    "                rules.append((list(lhs), list(rhs)))\n",
    "    print(\"Precision Rules: \", rules[:10])\n",
    "    return rules\n",
    "\n",
    "# Define recall_rules function\n",
    "def recall_rules(frequent_itemsets):\n",
    "    rules = []\n",
    "    for itemset, count in frequent_itemsets.items():\n",
    "        if count > 90:  # Check if itemset occurs more than 10 times\n",
    "            for i in range(1, len(itemset)):\n",
    "                lhs = itemset[:i]\n",
    "                #print(\"lhs:\", lhs)\n",
    "                rhs = itemset[i:]\n",
    "                #print(\"rhs:\", rhs)\n",
    "                rules.append((list(lhs), list(rhs)))\n",
    "    print(\"Recall Rules: \", rules[:10])\n",
    "    return rules\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "MapReduce",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 99,260 orders\n",
      "Keys output by mapper: 4,619,981 [steps: 4,619,981]\n",
      "Map 1 took 17 seconds\n",
      "Frequent itemsets: 4,619,981 [steps: 9,239,962]\n",
      "Reduce 1 took 11 seconds\n",
      "Keys output by mapper: 4,619,981 [steps: 16,580,595]\n",
      "Map 2 took 20 seconds\n",
      "Frequent itemsets: 4,619,981 [steps: 21,200,576]\n",
      "Reduce 2 took 12 seconds\n",
      "Precision Rules:  [([24838], [21903]), ([21903], [46667]), ([13176], [27966]), ([13176], [6184]), ([13176], [47209]), ([27966], [47209]), ([24852], [31717]), ([24852], [47766]), ([24852], [4605]), ([24852], [21137])]\n",
      "Recall Rules:  [([28985], [17794]), ([24838], [21903]), ([21903], [46667]), ([13176], [27966]), ([13176], [6184]), ([13176], [47209]), ([27966], [47209]), ([24852], [31717]), ([24852], [47766]), ([24852], [4605])]\n",
      "Rules created (precision): 1,157\n",
      "Rules created (recall): 1,403\n",
      "MapReduce total time=61 s, steps=21,200,576\n"
     ]
    }
   ],
   "source": [
    "# Reads in the data file to be used to extract the association rules\n",
    "import time\n",
    "\n",
    "product_orders = pd.read_csv(os.path.join('..', 'resource', 'asnlib', 'publicdata', 'order_products__prior.csv.bz2'),\n",
    "                             nrows=1000001)\n",
    "\n",
    "baskets = product_orders.groupby(['order_id'])['product_id']\n",
    "itemsets = {}\n",
    "print(f'Using {len(baskets):,} orders')\n",
    "\n",
    "assert len(stages) % 2 == 0, 'There should be an even number of stages (i.e., matching pairs of map and reduce)'\n",
    "\n",
    "# Serialized MapReduce\n",
    "map_phase = True\n",
    "steps = 0\n",
    "start_whole = time.time()\n",
    "for stage_num, worker_fun in enumerate(stages):\n",
    "    start = time.time()\n",
    "    if map_phase:\n",
    "        map_out = {}\n",
    "        for order_id, products in baskets:\n",
    "            for key, value in worker_fun(order_id, list(products), itemsets):\n",
    "                # Accumulate list of values for each key\n",
    "                try:\n",
    "                    map_out[key].append(value)\n",
    "                except KeyError:\n",
    "                    map_out[key] = [value]\n",
    "                steps += 1\n",
    "        print(f'Keys output by mapper: {len(map_out):,} [steps: {steps:,}]')\n",
    "    else:\n",
    "        for key, value in map_out.items():\n",
    "            for new_key, new_value in worker_fun(key, value):\n",
    "                itemsets[new_key] = new_value\n",
    "                steps += 1\n",
    "        print(f'Frequent itemsets: {len(itemsets):,} [steps: {steps:,}]')\n",
    "    stage_time = round(time.time()-start)\n",
    "    print(f'{\"Map\" if map_phase else \"Reduce\"} {stage_num//2+1} took {stage_time:d} seconds')\n",
    "    map_phase = not map_phase\n",
    "# Generate rules\n",
    "rules_p = precision_rules(itemsets)\n",
    "rules_r = recall_rules(itemsets)\n",
    "duration = int(round(time.time()-start_whole))\n",
    "print(f'Rules created (precision): {len(rules_p):,}')\n",
    "print(f'Rules created (recall): {len(rules_r):,}')\n",
    "print(f'MapReduce total time={duration:,} s, steps={steps:,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Rule Extraction",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 938 orders, spanning 4,660 products\n",
      "Rules fired 66,953 times\n",
      "Precision-oriented rules have a TP rate of 1.90/order, and a FP rate of 46.81/order\n",
      "Rules fired 78,511 times\n",
      "Recall-oriented rules have a TP rate of 2.02/order, and a FP rate of 54.64/order\n"
     ]
    }
   ],
   "source": [
    "def check_rules(rules):\n",
    "    \"\"\"Make sure rules are well-formed\"\"\"\n",
    "    for i, rule in enumerate(rules):\n",
    "        assert len(rule) == 2, f'Rule {rule} is not a list/tuple of length 2 (i.e., LHS and RHS)'\n",
    "        LHS, RHS = rule\n",
    "        if isinstance(LHS, int):\n",
    "            LHS = set(LHS)\n",
    "        if isinstance(RHS, int):\n",
    "            RHS = set(RHS)\n",
    "        rules[i] = (set(LHS), set(RHS))\n",
    "        overlap = rules[i][0] & rules[i][1]\n",
    "        assert len(overlap) == 0, f'Overlapping LHS and RHS: {\", \".join(sorted(overlap))}'\n",
    "    \n",
    "def evaluate_rules(rules, baskets):\n",
    "    rule_firings = 0\n",
    "    tp = fp = 0\n",
    "    for order, product_series in baskets:\n",
    "        # Do any rules match?\n",
    "        product_set = set(product_series)\n",
    "        predictions = set()\n",
    "        for LHS, RHS in rules:\n",
    "            is_fired = len(product_set & LHS) == len(LHS)\n",
    "            if is_fired:\n",
    "                # Rule fires\n",
    "                rule_firings += 1\n",
    "                predictions |= RHS\n",
    "        # Predicted items that appear in order\n",
    "        tp += len(predictions & product_set)\n",
    "        # Predicted items that do not appear in order\n",
    "        fp += len(predictions - product_set)\n",
    "    print(f'Rules fired {rule_firings:,} times')\n",
    "    return tp/len(baskets), fp/len(baskets)\n",
    "\n",
    "check_rules(rules_p)\n",
    "check_rules(rules_r)\n",
    "# Test rules on a separate data set\n",
    "test_orders = pd.read_csv(os.path.join('..', 'resource', 'asnlib', 'publicdata', 'order_products__train.csv.bz2'),\n",
    "                          nrows=9998)\n",
    "baskets = test_orders.groupby(['order_id'])['product_id']\n",
    "products = set(test_orders['product_id'].unique())\n",
    "print(f'Testing {len(baskets):,} orders, spanning {len(products):,} products')\n",
    "\n",
    "tp_rate_p, fp_rate_p = evaluate_rules(rules_p, baskets) \n",
    "print(f'Precision-oriented rules have a TP rate of {tp_rate_p:.02f}/order, and a FP rate of {fp_rate_p:.02f}/order')\n",
    "tp_rate_r, fp_rate_r = evaluate_rules(rules_r, baskets) \n",
    "print(f'Recall-oriented rules have a TP rate of {tp_rate_r:.02f}/order, and a FP rate of {fp_rate_r:.02f}/order')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Precision Good",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tp_rate_p > 0.5 and fp_rate_p < 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Precision Great",
     "locked": true,
     "points": "25",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tp_rate_p > 1 and fp_rate_p < 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Recall Good",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tp_rate_r > 1 and fp_rate_r < 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Recall Great",
     "locked": true,
     "points": "25",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tp_rate_r > 2 and fp_rate_r < 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
